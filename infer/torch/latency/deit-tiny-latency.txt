Using cache found in /root/.cache/torch/hub/facebookresearch_deit_main
----------------------------
deit_tiny_distilled_patch16_224
     Batch Size: 1
        Warm up: 50 iteraion
    Start timing: 1000 iteration
Iteration 100/1000, avg batch time 38.04 ms
Iteration 200/1000, avg batch time 38.14 ms
Iteration 300/1000, avg batch time 38.30 ms
Iteration 400/1000, avg batch time 38.27 ms
Iteration 500/1000, avg batch time 38.27 ms
Iteration 600/1000, avg batch time 38.26 ms
Iteration 700/1000, avg batch time 38.23 ms
Iteration 800/1000, avg batch time 38.21 ms
Iteration 900/1000, avg batch time 38.19 ms
Iteration 1000/1000, avg batch time 38.18 ms
      Input shape: torch.Size([1, 3, 224, 224])
     Output shape: torch.Size([1, 1000])
Avg batch time: 38.18 ms
Latency per query: 38.18 ms
----------------------------
----------------------------
deit_tiny_distilled_patch16_224
     Batch Size: 2
        Warm up: 50 iteraion
    Start timing: 500 iteration
Iteration 50/500, avg batch time 77.75 ms
Iteration 100/500, avg batch time 77.75 ms
Iteration 150/500, avg batch time 77.75 ms
Iteration 200/500, avg batch time 77.75 ms
Iteration 250/500, avg batch time 77.75 ms
Iteration 300/500, avg batch time 77.75 ms
Iteration 350/500, avg batch time 77.75 ms
Iteration 400/500, avg batch time 77.75 ms
Iteration 450/500, avg batch time 77.76 ms
Iteration 500/500, avg batch time 77.76 ms
      Input shape: torch.Size([2, 3, 224, 224])
     Output shape: torch.Size([2, 1000])
Avg batch time: 77.76 ms
Latency per query: 38.88 ms
----------------------------
----------------------------
deit_tiny_distilled_patch16_224
     Batch Size: 4
        Warm up: 50 iteraion
    Start timing: 250 iteration
Iteration 25/250, avg batch time 144.52 ms
Iteration 50/250, avg batch time 144.53 ms
Iteration 75/250, avg batch time 144.54 ms
Iteration 100/250, avg batch time 144.55 ms
Iteration 125/250, avg batch time 144.55 ms
Iteration 150/250, avg batch time 144.55 ms
Iteration 175/250, avg batch time 144.55 ms
Iteration 200/250, avg batch time 144.55 ms
Iteration 225/250, avg batch time 144.55 ms
Iteration 250/250, avg batch time 144.55 ms
      Input shape: torch.Size([4, 3, 224, 224])
     Output shape: torch.Size([4, 1000])
Avg batch time: 144.55 ms
Latency per query: 36.14 ms
----------------------------
Using cache found in /root/.cache/torch/hub/facebookresearch_deit_main
----------------------------
deit_tiny_distilled_patch16_224
     Batch Size: 8
        Warm up: 50 iteraion
    Start timing: 125 iteration
Iteration 25/125, avg batch time 278.42 ms
Iteration 50/125, avg batch time 278.47 ms
Iteration 75/125, avg batch time 278.55 ms
Iteration 100/125, avg batch time 278.53 ms
Iteration 125/125, avg batch time 278.52 ms
      Input shape: torch.Size([8, 3, 224, 224])
     Output shape: torch.Size([8, 1000])
Avg batch time: 278.52 ms
Latency per query: 34.81 ms
----------------------------
----------------------------
deit_tiny_distilled_patch16_224
     Batch Size: 12
        Warm up: 50 iteraion
    Start timing: 83 iteration
      Input shape: torch.Size([12, 3, 224, 224])
     Output shape: torch.Size([12, 1000])
Avg batch time: 411.68 ms
Latency per query: 34.31 ms
----------------------------
Using cache found in /root/.cache/torch/hub/facebookresearch_deit_main
----------------------------
deit_tiny_distilled_patch16_224
     Batch Size: 16
        Warm up: 50 iteraion
    Start timing: 62 iteration
      Input shape: torch.Size([16, 3, 224, 224])
     Output shape: torch.Size([16, 1000])
Avg batch time: 547.23 ms
Latency per query: 34.20 ms
----------------------------
----------------------------
deit_tiny_distilled_patch16_224
     Batch Size: 32
        Warm up: 50 iteraion
    Start timing: 31 iteration
      Input shape: torch.Size([32, 3, 224, 224])
     Output shape: torch.Size([32, 1000])
Avg batch time: 1096.01 ms
Latency per query: 34.25 ms
----------------------------
